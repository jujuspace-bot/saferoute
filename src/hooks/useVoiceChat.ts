import { useState, useCallback, useRef } from 'react';
import { ChatMessage, sendChatMessage, NavigationContext } from '../services/ai';
import { speak, stopSpeaking } from '../services/voice';
import { useAppStore } from '../stores/appStore';

/**
 * ìŒì„± ëŒ€í™” í›…: STT â†’ AI â†’ TTS íŒŒì´í”„ë¼ì¸
 *
 * ì°¸ê³ : expo-speechëŠ” TTSë§Œ ì§€ì›. STTëŠ” ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”.
 * í˜„ì¬ëŠ” STT placeholderë¡œ êµ¬í˜„. ì‹¤ì œ ì ìš© ì‹œ @react-native-voice/voice ë“± ì‚¬ìš©.
 */

interface UseVoiceChatOptions {
  onTranscript?: (text: string) => void;
  onAiReply?: (text: string) => void;
  onError?: (error: string) => void;
}

interface UseVoiceChatReturn {
  isRecording: boolean;
  isProcessing: boolean;
  isSpeaking: boolean;
  startRecording: () => void;
  stopRecording: () => Promise<string | null>;
  sendVoiceMessage: (transcript: string, chatHistory: ChatMessage[]) => Promise<string | null>;
  cancelSpeaking: () => Promise<void>;
}

export function useVoiceChat(options?: UseVoiceChatOptions): UseVoiceChatReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const recordingStartTime = useRef<number>(0);

  const {
    currentLocation,
    destination,
    routeSteps,
    currentStepIndex,
    isDeviated,
    deviationDistance,
    isNavigating,
  } = useAppStore();

  const buildContext = useCallback((): NavigationContext => ({
    currentLocation: currentLocation
      ? { latitude: currentLocation.latitude, longitude: currentLocation.longitude }
      : null,
    destination: destination ?? undefined,
    currentStep: routeSteps[currentStepIndex]?.instruction,
    currentStepIndex,
    totalSteps: routeSteps.length,
    isDeviated,
    deviationDistance,
    isNavigating,
    routeSteps: routeSteps.map((s) => ({
      instruction: s.instruction,
      type: s.type,
      stopName: s.stopName,
      lineNumber: s.lineNumber,
    })),
  }), [currentLocation, destination, routeSteps, currentStepIndex, isDeviated, deviationDistance, isNavigating]);

  const startRecording = useCallback(() => {
    setIsRecording(true);
    recordingStartTime.current = Date.now();
    // TODO: ì‹¤ì œ STT ë…¹ìŒ ì‹œì‘
    // Voice.start('ko-KR');
  }, []);

  const stopRecording = useCallback(async (): Promise<string | null> => {
    setIsRecording(false);
    const duration = Date.now() - recordingStartTime.current;

    // ë„ˆë¬´ ì§§ì€ ë…¹ìŒì€ ë¬´ì‹œ (500ms ë¯¸ë§Œ)
    if (duration < 500) {
      return null;
    }

    // TODO: ì‹¤ì œ STT ê²°ê³¼ ë°˜í™˜
    // const result = await Voice.stop();
    // return result;
    
    // Placeholder: ì‹¤ì œ STT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—°ë™ ì‹œ êµì²´
    return null;
  }, []);

  const sendVoiceMessage = useCallback(
    async (transcript: string, chatHistory: ChatMessage[]): Promise<string | null> => {
      if (!transcript.trim()) return null;

      setIsProcessing(true);
      options?.onTranscript?.(transcript);

      try {
        const context = buildContext();
        const history: ChatMessage[] = [
          ...chatHistory.slice(-6).map(({ role, content }) => ({ role, content })),
          { role: 'user' as const, content: transcript },
        ];

        const reply = await sendChatMessage(history, context);
        options?.onAiReply?.(reply);

        // TTSë¡œ ì½ì–´ì£¼ê¸°
        setIsSpeaking(true);
        await speak(reply);
        setIsSpeaking(false);

        return reply;
      } catch {
        const errorMsg = 'ìŒì„± ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ìš” ğŸ™';
        options?.onError?.(errorMsg);
        return null;
      } finally {
        setIsProcessing(false);
      }
    },
    [buildContext, options],
  );

  const cancelSpeaking = useCallback(async () => {
    await stopSpeaking();
    setIsSpeaking(false);
  }, []);

  return {
    isRecording,
    isProcessing,
    isSpeaking,
    startRecording,
    stopRecording,
    sendVoiceMessage,
    cancelSpeaking,
  };
}
