import { APP_CONFIG } from '../constants/config';

const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ë°œë‹¬ì¥ì• ì¸ê³¼ ë…¸ì¸ì˜ ëŒ€ì¤‘êµí†µ ì´ë™ì„ ë•ëŠ” ì¹œì ˆí•œ AI ë„ìš°ë¯¸ "ë£¨ë¯¸"ì…ë‹ˆë‹¤.

ê·œì¹™:
- í•­ìƒ 3ë¬¸ì¥ ì´ë‚´ë¡œ ì§§ê²Œ ë‹µë³€
- ì‰¬ìš´ ë‹¨ì–´ë§Œ ì‚¬ìš© (ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ)
- ì¹œê·¼í•˜ê³  ì•ˆì‹¬ì‹œí‚¤ëŠ” ë§íˆ¬ ì‚¬ìš©
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©
- ìœ„ì¹˜ì™€ ê²½ë¡œ ê´€ë ¨ ì§ˆë¬¸ì— ì§‘ì¤‘

ì˜ˆì‹œ:
- "ì˜ ê°€ê³  ìˆì–´ìš”! ë‹¤ìŒ ì •ë¥˜ì¥ì—ì„œ ë‚´ë¦¬ë©´ ë¼ìš” ğŸ˜Š"
- "ê´œì°®ì•„ìš”! ì œê°€ ë‹¤ì‹œ ê¸¸ì„ ì•Œë ¤ì¤„ê²Œìš” ğŸ—ºï¸"
- "3ë²ˆ ì¶œêµ¬ë¡œ ë‚˜ê°€ë©´ ë°”ë¡œ ë³´ì—¬ìš”! ì¡°ê¸ˆë§Œ ë” ê°€ìš” ğŸ’ª"`;

export interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
}

// AI ëŒ€í™” (OpenAI API)
export async function sendChatMessage(
  messages: ChatMessage[],
  context?: {
    currentLocation?: string;
    destination?: string;
    currentStep?: string;
    isDeviated?: boolean;
  }
): Promise<string> {
  const contextMessage = context
    ? `\n\n[í˜„ì¬ ìƒí™©] ${context.isDeviated ? 'âš ï¸ ê²½ë¡œ ì´íƒˆ ì¤‘!' : 'ì •ìƒ ì´ë™ ì¤‘'}` +
      (context.currentStep ? ` | í˜„ì¬: ${context.currentStep}` : '') +
      (context.destination ? ` | ëª©ì ì§€: ${context.destination}` : '')
    : '';

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer YOUR_OPENAI_API_KEY`, // TODO: í™˜ê²½ë³€ìˆ˜ë¡œ êµì²´
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: SYSTEM_PROMPT + contextMessage },
          ...messages,
        ],
        max_tokens: 200,
        temperature: 0.7,
      }),
    });

    const data = await response.json();
    return data.choices[0]?.message?.content || 'ë¯¸ì•ˆí•´ìš”, ë‹¤ì‹œ ë§í•´ì¤„ë˜ìš”? ğŸ™';
  } catch {
    return 'ì¸í„°ë„· ì—°ê²°ì´ ë¶ˆì•ˆì •í•´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” ğŸ“¶';
  }
}
